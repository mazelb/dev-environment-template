services:
  # FastAPI Application
  api:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: ${PROJECT_NAME:-rag}-api
    ports:
      - '8000:8000'
    environment:
      # Database
      - POSTGRES_DATABASE_URL=postgresql+psycopg2://${POSTGRES_USER:-rag_user}:${POSTGRES_PASSWORD:-rag_password}@postgres:5432/${POSTGRES_DB:-rag_db}
      # Search & Vector
      - OPENSEARCH_HOST=http://opensearch:9200
      - OPENSEARCH__HOST=http://opensearch:9200
      - OPENSEARCH__INDEX_NAME=documents
      - OPENSEARCH__CHUNK_INDEX_SUFFIX=chunks
      - OPENSEARCH__VECTOR_DIMENSION=1024
      # LLM
      - OLLAMA_HOST=http://ollama:11434
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama2}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-nomic-embed-text}
      # Cache & Performance
      - REDIS__HOST=redis
      - REDIS__PORT=6379
      - REDIS__DB=0
      # Observability
      - LANGFUSE__HOST=http://langfuse:3000
      - LANGFUSE__PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY:-}
      - LANGFUSE__SECRET_KEY=${LANGFUSE_SECRET_KEY:-}
      # App Config
      - DEBUG=${DEBUG:-false}
      - ENVIRONMENT=${ENVIRONMENT:-development}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      opensearch:
        condition: service_healthy
      ollama:
        condition: service_started
    healthcheck:
      test:
        [
          'CMD-SHELL',
          'python -c "import urllib.request;
          urllib.request.urlopen(''http://localhost:8000/api/v1/health'')"',
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    volumes:
      - ./src:/app/src
      - ./uploads:/app/uploads
      - ./data:/app/data
    restart: unless-stopped
    networks:
      - rag-network

  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: ${PROJECT_NAME:-rag}-postgres
    environment:
      - POSTGRES_DB=${POSTGRES_DB:-rag_db}
      - POSTGRES_USER=${POSTGRES_USER:-rag_user}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-rag_password}
      - POSTGRES_HOST_AUTH_METHOD=password
      - PGDATA=/var/lib/postgresql/data/pgdata
    ports:
      - '5432:5432'
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/postgres-init:/docker-entrypoint-initdb.d
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U ${POSTGRES_USER:-rag_user} -d ${POSTGRES_DB:-rag_db}']
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 30s
    restart: unless-stopped
    networks:
      - rag-network

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: ${PROJECT_NAME:-rag}-redis
    ports:
      - '6379:6379'
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - rag-network

  # OpenSearch Vector & Search Database
  opensearch:
    image: opensearchproject/opensearch:2.19.0
    container_name: ${PROJECT_NAME:-rag}-opensearch
    environment:
      - discovery.type=single-node
      - OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m
      - DISABLE_SECURITY_PLUGIN=true
      - bootstrap.memory_lock=true
    ports:
      - '9200:9200'
      - '9600:9600'
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - opensearch_data:/usr/share/opensearch/data
    healthcheck:
      test: ['CMD-SHELL', 'curl -f http://localhost:9200/_cluster/health || exit 1']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    networks:
      - rag-network

  # OpenSearch Dashboards
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:2.19.0
    container_name: ${PROJECT_NAME:-rag}-dashboards
    ports:
      - '5601:5601'
    environment:
      - OPENSEARCH_HOSTS=http://opensearch:9200
      - DISABLE_SECURITY_DASHBOARDS_PLUGIN=true
    depends_on:
      opensearch:
        condition: service_healthy
    healthcheck:
      test: ['CMD-SHELL', 'curl -f http://localhost:5601/api/status || exit 1']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - rag-network

  # Ollama LLM Server
  ollama:
    image: ollama/ollama:0.11.2
    container_name: ${PROJECT_NAME:-rag}-ollama
    ports:
      - '11434:11434'
    volumes:
      - ollama_data:/root/.ollama
    healthcheck:
      test: ['CMD', 'ollama', 'list']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    networks:
      - rag-network

  # Langfuse Observability Platform
  langfuse:
    image: langfuse/langfuse:2
    container_name: ${PROJECT_NAME:-rag}-langfuse
    depends_on:
      langfuse-postgres:
        condition: service_healthy
    ports:
      - '3000:3000'
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://langfuse:langfuse@langfuse-postgres:5432/langfuse
      - NEXTAUTH_URL=http://localhost:3000
      - NEXTAUTH_SECRET=${LANGFUSE_NEXTAUTH_SECRET:-changeThisToASecureRandomString32CharsMin}
      - SALT=${LANGFUSE_SALT:-changeThisToAnotherSecureRandomString}
      - TELEMETRY_ENABLED=false
      - NEXT_PUBLIC_SIGN_UP_DISABLED=false
    healthcheck:
      test: ['CMD-SHELL', 'curl -f http://localhost:3000/api/public/health || exit 1']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    networks:
      - rag-network

  # Langfuse PostgreSQL Database
  langfuse-postgres:
    image: postgres:16-alpine
    container_name: ${PROJECT_NAME:-rag}-langfuse-postgres
    environment:
      - POSTGRES_DB=langfuse
      - POSTGRES_USER=langfuse
      - POSTGRES_PASSWORD=langfuse
      - POSTGRES_HOST_AUTH_METHOD=password
    volumes:
      - langfuse_postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U langfuse -d langfuse']
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 30s
    restart: unless-stopped
    networks:
      - rag-network

  # ClickHouse - Analytics Database for Langfuse (Optional)
  # Uncomment to enable advanced analytics features
  # clickhouse:
  #   image: clickhouse/clickhouse-server:24.8-alpine
  #   container_name: ${PROJECT_NAME:-rag}-clickhouse
  #   environment:
  #     - CLICKHOUSE_DB=langfuse
  #     - CLICKHOUSE_USER=langfuse
  #     - CLICKHOUSE_PASSWORD=langfuse
  #     - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
  #   ports:
  #     - '8123:8123'
  #     - '9000:9000'
  #   volumes:
  #     - clickhouse_data:/var/lib/clickhouse
  #   healthcheck:
  #     test: ['CMD', 'wget', '--spider', '-q', 'localhost:8123/ping']
  #     interval: 30s
  #     timeout: 5s
  #     retries: 3
  #     start_period: 30s
  #   restart: unless-stopped
  #   networks:
  #     - rag-network
  #   ulimits:
  #     nofile:
  #       soft: 262144
  #       hard: 262144

  # Apache Airflow - Workflow Orchestration
  airflow-init:
    build:
      context: ./airflow
      dockerfile: Dockerfile
    container_name: ${PROJECT_NAME:-rag}-airflow-init
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY:-}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
      - _AIRFLOW_DB_MIGRATE=true
      - _AIRFLOW_WWW_USER_CREATE=true
      - _AIRFLOW_WWW_USER_USERNAME=${AIRFLOW_USERNAME:-admin}
      - _AIRFLOW_WWW_USER_PASSWORD=${AIRFLOW_PASSWORD:-admin}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/plugins:/opt/airflow/plugins
      - ./src:/opt/airflow/src
      - airflow_logs:/opt/airflow/logs
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - rag-network
    command: >
      bash -c "airflow db migrate &&
               airflow users create --username $${_AIRFLOW_WWW_USER_USERNAME} --password
      $${_AIRFLOW_WWW_USER_PASSWORD} --firstname Admin --lastname User --role Admin --email
      admin@example.com || true"

  airflow-webserver:
    build:
      context: ./airflow
      dockerfile: Dockerfile
    container_name: ${PROJECT_NAME:-rag}-airflow-webserver
    ports:
      - '8080:8080'
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY:-}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
      - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW_WEBSERVER_SECRET_KEY:-}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/plugins:/opt/airflow/plugins
      - ./src:/opt/airflow/src
      - airflow_logs:/opt/airflow/logs
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
    healthcheck:
      test: ['CMD', 'curl', '--fail', 'http://localhost:8080/health']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    networks:
      - rag-network
    command: webserver

  airflow-scheduler:
    build:
      context: ./airflow
      dockerfile: Dockerfile
    container_name: ${PROJECT_NAME:-rag}-airflow-scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY:-}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/plugins:/opt/airflow/plugins
      - ./src:/opt/airflow/src
      - airflow_logs:/opt/airflow/logs
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
    healthcheck:
      test:
        ['CMD', 'airflow', 'jobs', 'check', '--job-type', 'SchedulerJob', '--hostname', '$HOSTNAME']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    networks:
      - rag-network
    command: scheduler

volumes:
  postgres_data:
  redis_data:
  opensearch_data:
  ollama_data:
  langfuse_postgres_data:
  airflow_logs:
  # clickhouse_data:  # Uncomment if using ClickHouse

networks:
  rag-network:
    driver: bridge
